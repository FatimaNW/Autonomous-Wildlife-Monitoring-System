{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Install the required packages\n",
        "!pip install ultralytics pillow opencv-python-headless\n",
        "\n",
        "import cv2\n",
        "from ultralytics import YOLO\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# Path to the video file\n",
        "video_path = \"/content/obj detection1.mp4\"  # Change this to your video file path\n",
        "\n",
        "# Load the Haar cascade file for full-body detection\n",
        "fullbody_cascade_path = 'haarcascade_fullbody.xml'\n",
        "fullbody_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + fullbody_cascade_path)\n",
        "\n",
        "# Function to process and annotate video frames\n",
        "def detect_animals_in_video(video_path):\n",
        "    # Load YOLOv8 model\n",
        "    model = YOLO('yolov8s.pt')  # Use 'yolov8s.pt' for the smallest version\n",
        "\n",
        "    # Open the video file\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    if not cap.isOpened():\n",
        "        print(f\"Error: Unable to open video file {video_path}\")\n",
        "        return\n",
        "\n",
        "    # Define the codec and create VideoWriter object\n",
        "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "    out = cv2.VideoWriter('output_video.mp4', fourcc, 20.0, (int(cap.get(3)), int(cap.get(4))))\n",
        "\n",
        "    while cap.isOpened():\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "        # Detect full bodies using Haar cascade\n",
        "        fullbodies = fullbody_cascade.detectMultiScale(gray, scaleFactor=1.05, minNeighbors=3, minSize=(60, 60), flags=cv2.CASCADE_SCALE_IMAGE)\n",
        "\n",
        "        # Draw rectangles around detected full bodies\n",
        "        for (x, y, w, h) in fullbodies:\n",
        "            cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
        "\n",
        "        # Use YOLOv8 model to detect animals\n",
        "        results = model(frame)\n",
        "        label_count = {}  # Dictionary to keep track of label counts\n",
        "\n",
        "        for result in results:\n",
        "            for box in result.boxes:\n",
        "                # Access class ID, confidence, and bounding box coordinates\n",
        "                cls_id = int(box.cls[0])\n",
        "                label = model.names[cls_id]\n",
        "                confidence = box.conf[0]\n",
        "\n",
        "                if label in ['zebra', 'elephant', 'bear', 'giraffe']:  # Add or modify the list as needed\n",
        "                    x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
        "\n",
        "                    # Increment the label count or initialize it\n",
        "                    if label not in label_count:\n",
        "                        label_count[label] = 1\n",
        "                    else:\n",
        "                        label_count[label] += 1\n",
        "\n",
        "                    # Create the label with index if there are multiple instances\n",
        "                    label_with_index = f\"{label}_{label_count[label]}\" if label_count[label] > 1 else f\"{label}_1\"\n",
        "\n",
        "                    # Draw rectangle and put text\n",
        "                    cv2.rectangle(frame, (x1, y1), (x2, y2), (255, 0, 0), 2)\n",
        "                    text = f\"{label_with_index} ({confidence:.2f})\"\n",
        "                    # Calculate text background\n",
        "                    (text_width, text_height), baseline = cv2.getTextSize(text, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 2)\n",
        "                    cv2.rectangle(frame, (x1, y1 - text_height - 2 * baseline), (x1 + text_width, y1), (255, 255, 255), -1)\n",
        "                    cv2.putText(frame, text, (x1, y1 - baseline), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)  # Blue color and bold text\n",
        "\n",
        "        # Write the frame to the output video file\n",
        "        out.write(frame)\n",
        "\n",
        "    # Release video objects\n",
        "    cap.release()\n",
        "    out.release()\n",
        "    cv2.destroyAllWindows()\n",
        "\n",
        "    # Display the output video\n",
        "    display_output_video('output_video.mp4')\n",
        "\n",
        "# Function to display the output video\n",
        "def display_output_video(output_video_path):\n",
        "    cap = cv2.VideoCapture(output_video_path)\n",
        "\n",
        "    while cap.isOpened():\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        # Display the frame using cv2_imshow\n",
        "        cv2_imshow(frame)\n",
        "\n",
        "    cap.release()\n",
        "    cv2.destroyAllWindows()\n",
        "\n",
        "# Example usage\n",
        "detect_animals_in_video(video_path)\n"
      ],
      "metadata": {
        "id": "HkAvdW5U_k_t"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}